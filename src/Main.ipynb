{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        self.stop_words = set(STOP_WORDS)\n",
    "        self.stop_words.update(string.punctuation)\n",
    "        self.stop_words.remove('not')\n",
    "        \n",
    "        self.docs = []\n",
    "        self.splits = []\n",
    "        \n",
    "    def split_into_sents(self, review):\n",
    "        if not isinstance(review, spacy.tokens.doc.Doc):\n",
    "            review = self.nlp(review)\n",
    "        \n",
    "        sents = []\n",
    "        for sentence in review.sents:\n",
    "            start = 0\n",
    "            counter = 0\n",
    "            print(\"Sentence: \", sentence)\n",
    "            for token in sentence:\n",
    "                # 89 -> Conjunctions,\n",
    "                # 97 -> Punctuations\n",
    "                if token.pos in [89, 97] or token.text.strip() == ',':\n",
    "                    if counter > start: \n",
    "                        sents.append(sentence[start: counter])\n",
    "                    start = counter + 1\n",
    "                counter += 1\n",
    "        return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  I liked the food, but service was awful.\n",
      "Sentence:  Ambience was damn poor.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[I liked the food, service was awful, Ambience was damn poor]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = PreProcessor()\n",
    "p.split_into_sents(\"I liked the food, but service was awful. Ambience was damn poor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "I 95 PRON pronoun nsubj\n",
      "did 87 AUX auxiliary aux\n",
      "n't 94 PART particle neg\n",
      "like 100 VERB verb ROOT\n",
      "the 90 DET determiner det\n",
      "food 92 NOUN noun dobj\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I didn't like the food\")\n",
    "print(type(doc))\n",
    "for token in doc:\n",
    "    print(token, token.pos, token.pos_, spacy.explain(token.pos_), token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 95 PRON pronoun nsubj\n",
      "did 87 AUX auxiliary aux\n",
      "not 94 PART particle neg\n",
      "like 100 VERB verb ROOT\n",
      "the 90 DET determiner det\n",
      "food 92 NOUN noun dobj\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I did not like the food\")\n",
    "for token in doc:\n",
    "    print(token, token.pos, token.pos_, spacy.explain(token.pos_), token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food 92 NOUN noun nsubj\n",
      "was 87 AUX auxiliary ROOT\n",
      "pretty 86 ADV adverb advmod\n",
      "bad 84 ADJ adjective acomp\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"food was pretty bad\")\n",
    "for token in doc:\n",
    "    print(token, token.pos, token.pos_, spacy.explain(token.pos_), token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food 92 NOUN noun nsubj\n",
      "was 87 AUX auxiliary ROOT\n",
      "good 84 ADJ adjective acomp\n",
      ", 97 PUNCT punctuation punct\n",
      "but 89 CCONJ coordinating conjunction cc\n",
      "service 92 NOUN noun nsubj\n",
      "was 87 AUX auxiliary conj\n",
      "awful 84 ADJ adjective acomp\n",
      ". 97 PUNCT punctuation punct\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"food was good, but service was awful.\")\n",
    "for token in doc:\n",
    "    print(token, token.pos, token.pos_, spacy.explain(token.pos_), token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = PreProcessor()\n",
    "p.split_into_sents(\"I didn't like the food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
